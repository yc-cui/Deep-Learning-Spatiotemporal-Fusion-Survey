# A Decade of Deep Learning for Remote Sensing Spatiotemporal Fusion: Advances, Challenges, and Opportunities

This repository provides a comprehensive implementation of deep learning models for remote sensing spatiotemporal fusion, featuring state-of-the-art architectures and evaluation frameworks.

## ğŸ“‹ Table of Contents

- [Environment Setup](#ğŸš€-environment-setup)
- [Dataset Configuration](#ğŸ“Š-dataset-configuration)
- [Model Architecture](#ğŸ—ï¸-model-architecture)
- [Training and Testing](#ğŸ¯-training-and-testing)
- [Evaluation Metrics](#ğŸ“ˆ-evaluation-metrics)
- [Logging and Monitoring](#ğŸ“Š-logging-and-monitoring)
- [Citation](#ğŸ“š-citation)

## ğŸš€ Environment Setup

### Prerequisites
- Python 3.8+
- CUDA 11.8+
- PyTorch 2.0+

### Installation

1. **Clone the repository:**
```bash
git clone https://github.com/yc-cui/Deep-Learning-Spatiotemporal-Fusion-Survey
cd code
```

2. **Create and activate conda environment:**
```bash
# Create environment from YAML file
conda env create -f stf-fusion.yaml

# Activate environment
conda activate stf-fusion
```


### Environment Details
The `stf-fusion.yaml` file contains all necessary dependencies including:
- PyTorch with CUDA support
- PyTorch Lightning for training
- TensorBoard and WandB for logging
- Image processing libraries (tifffile, PIL)
- Scientific computing (numpy, scipy)

## ğŸ“Š Dataset Configuration

### Supported Datasets

| Dataset | Bands | Image Size | Normalized Value |
|---------|-------|------------|-----------|
| CIA | 6 | 1792Ã—1280 | 10000 |
| LGC | 6 | 2560Ã—3072 | 10000 |
| AHB | 6 | 2480Ã—2800 | 255 |
| DX | 6 | 1640Ã—1640 | 255 |
| TJ | 6 | 2100Ã—1970 | 255 |
| WH | 4 | 1000Ã—1000 | 10000 |
| IC | 4 | 1500Ã—1500 | 1.0 |
| BC | 4 | 1500Ã—1500 | 1.0 |

### Dataset Structure
```
data/
â”œâ”€â”€ CIA/
â”‚   â”œâ”€â”€ Landsat/     # High-resolution images
â”‚   â”‚   â”œâ”€â”€ L71093084_08420020401_HRF_modtran_surf_ref_agd66.tif
â”‚   â”‚   â”œâ”€â”€ L71093084_08420020410_HRF_modtran_surf_ref_agd66.tif
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ MODIS/       # Low-resolution images
â”‚       â”œâ”€â”€ MOD09GA_A2001290.sur_refl.tif
â”‚       â”œâ”€â”€ MOD09GA_A2002044.sur_refl.tif
â”‚       â””â”€â”€ ...
â”œâ”€â”€ LGC/
â”‚   â”œâ”€â”€ Landsat/
â”‚   â”‚   â”œâ”€â”€ 20050403_TM.tif
â”‚   â”‚   â”œâ”€â”€ 20041228_TM.tif
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ MODIS/
â”‚       â”œâ”€â”€ MOD09GA_A2005013.sur_refl.tif
â”‚       â”œâ”€â”€ MOD09GA_A2004347.sur_refl.tif
â”‚       â””â”€â”€ ...
â”œâ”€â”€ Datasets/
â”‚   â”œâ”€â”€ AHB/
â”‚   â”‚   â”œâ”€â”€ Landsat/
â”‚   â”‚   â”‚   â”œâ”€â”€ L_2015-6-21.tif
â”‚   â”‚   â”‚   â”œâ”€â”€ L_2017-6-10.tif
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ MODIS/
â”‚   â”‚       â”œâ”€â”€ M_2016-4-20.tif
â”‚   â”‚       â”œâ”€â”€ M_2017-7-28.tif
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”œâ”€â”€ Daxing/
â”‚   â””â”€â”€ Tianjin/
â”œâ”€â”€ Wuhan/
â”‚   â”œâ”€â”€ Landsat/
â”‚   â”‚   â”œâ”€â”€ G_20180109.tif
â”‚   â”‚   â”œâ”€â”€ G_20210118.tif
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ MODIS/
â”‚       â”œâ”€â”€ L_20210118.tif
â”‚       â”œâ”€â”€ L_20211220.tif
â”‚       â””â”€â”€ ...
â”œâ”€â”€ IC/
â”‚   â”œâ”€â”€ Landsat/
â”‚   â”‚   â”œâ”€â”€ S2_20220405.tif
â”‚   â”‚   â”œâ”€â”€ S2_20220505.tif
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ MODIS/
â”‚       â”œâ”€â”€ S3_20220105_real.tif
â”‚       â”œâ”€â”€ S3_20220604_real.tif
â”‚       â””â”€â”€ ...
â””â”€â”€ BC/
    â”œâ”€â”€ Landsat/
    â”‚   â”œâ”€â”€ S2_20220713.tif
    â”‚   â”œâ”€â”€ S2_20220822.tif
    â”‚   â””â”€â”€ ...
    â””â”€â”€ MODIS/
        â”œâ”€â”€ S3_20221001_real.tif
        â”œâ”€â”€ S3_20220713_real.tif
        â””â”€â”€ ...
```


## ğŸ—ï¸ Model Architecture

### Available Models

| Model | Architecture | Key Features |
|-------|--------------|--------------|
| **ECPW-STFN** | Parallel Wavelet + Refinement | Wavelet decomposition, parallel processing |
| **EDC-STFN** | Encoder-Decoder + Cross-Scale | Multi-scale feature fusion |
| **GAN-STFM** | Generative Adversarial Network | Adversarial training, realistic generation |
| **MLFF-GAN** | Multi-Level Feature Fusion GAN | Hierarchical feature learning |
| **SRSF_GAN** | Spatial Resolution Enhancement GAN | Spatial detail enhancement |
| **STFDiff** | Diffusion Model | Denoising diffusion process |
| **SwinSTFM** | Swin Transformer | Self-attention, hierarchical structure |

### Model Location
All models are located in `LibSTFv1/model/` with the following structure:
```
LibSTFv1/model/
â”œâ”€â”€ ECPW_STFN/
â”œâ”€â”€ EDCSTFN/
â”œâ”€â”€ GAN_STFM/
â”œâ”€â”€ MLFF_GAN/
â”œâ”€â”€ SRSF_GAN/
â”œâ”€â”€ STFDiff/
â”œâ”€â”€ SwinSTFM/
```

### ğŸš€ Adding Your Model
By following our standardized format, you can quickly integrate your model into the framework and compare results with other models.



## ğŸ¯ Training and Testing

### Quick Start

1. **Training and testing a model:**
```bash
python examples/ECPW_STFN.py \
    --dataset AHB \
    --epochs 500 \
    --batch_size 6 \
    --device 0 \
    --seed 42
```


**Note**: When testing only, you need to modify the example script by:
- Commenting out: `trainer.fit(model, dataset)`
- Uncommenting: `trainer.test(model, ckpt_path="path/to/checkpoint.ckpt", datamodule=dataset)`

### Training Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `--dataset` | AHB | Dataset name |
| `--epochs` | 500 | Number of training epochs |
| `--batch_size` | 6 | Batch size |
| `--device` | 0 | GPU device ID |
| `--seed` | 42 | Random seed |
| `--test_freq` | 10 | Validation frequency |
| `--num_workers` | 8 | Data loader workers |
| `--wandb` | False | Enable WandB logging |

### Example Training Commands

```bash
# Train ECPW_STFN on AHB dataset
python examples/ECPW_STFN.py --dataset AHB --epochs 500 --device 0

# Train SwinSTFM on CIA dataset with WandB
python examples/SwinSTFM.py --dataset CIA --epochs 300 --wandb --device 1

# Train GAN_STFM on LGC dataset
python examples/GAN_STFM.py --dataset LGC --epochs 400 --batch_size 4
```

## ğŸ“ˆ Evaluation Metrics

### Metrics Supported
- **MAE**: Mean Absolute Error
- **RMSE**: Root Mean Square Error
- **PSNR**: Peak Signal-to-Noise Ratio
- **SSIM**: Structural Similarity Index
- **SAM**: Spectral Angle Mapper
- **ERGAS**: Erreur Relative Globale Adimensionnelle de SynthÃ¨se
- **RASE**: Relative Average Spectral Error
- **UQI**: Universal Quality Index
- **SCC**: Spatial Correlation Coefficient
- **CC**: Cross Correlation
- **RÂ²**: Coefficient of Determination



## ğŸ“Š Logging and Monitoring

### Logging Options

Logs are automatically saved to `log/{dataset}/{model}/` directory

### Log Structure
```
log/
â”œâ”€â”€ AHB/
â”‚   â”œâ”€â”€ ECPW_STFN/
â”‚   â”‚   â”œâ”€â”€ log_m=STF.ECPW_STFNModel_sd=42_d=AHB/
â”‚   â”‚   â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â”‚   â”œâ”€â”€ logs/
â”‚   â”‚   â”‚   â””â”€â”€ metrics.csv
â”‚   â””â”€â”€ SwinSTFM/
â””â”€â”€ CIA/
```

## ğŸ“š Citation

If you use this code in your research, please cite our paper:

```bibtex
@misc{sun2025decadedeeplearningremote,
      title={A Decade of Deep Learning for Remote Sensing Spatiotemporal Fusion: Advances, Challenges, and Opportunities}, 
      author={Enzhe Sun and Yongchuan Cui and Peng Liu and Jining Yan},
      year={2025},
      eprint={2504.00901},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2504.00901}, 
}
```

## ğŸ¤ Contributing

We welcome contributions! Please feel free to submit issues and pull requests.

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Thanks to all contributors and researchers in the spatiotemporal fusion community
- Special thanks to the authors of the original datasets and baseline methods

## ğŸ“ Contact

For questions and issues:
- Email: yongchuancui@gmail.com
